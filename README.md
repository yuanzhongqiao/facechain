<div class="Box-sc-g0xbh4-0 bJMeLZ js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><p align="center" dir="auto">
     
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们的工作</font></font><a href="https://arxiv.org/abs/2403.01901" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain-ImagineID</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><a href="https://arxiv.org/abs/2403.06775" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain-SuDe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">被CVPR 2024录用！</font></font></p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">介绍</font></font></h1><a id="user-content-introduction" class="anchor" aria-label="永久链接：简介" href="#introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果您熟悉中文，可以阅读</font></font><a href="/modelscope/facechain/blob/main/README_ZH.md"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">中文版本的README</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain 是一个用于生成数字孪生的深度学习工具链。只需至少一张肖像照片，您就可以创建自己的数字孪生，并开始在不同的设置下生成个人肖像（现在支持多种风格！）。您可以通过 FaceChain 的 Python 脚本、熟悉的 Gradio 界面或 sd webui 训练您的 Digital-Twin 模型并生成照片。 FaceChain 由</font></font><a href="https://github.com/modelscope/modelscope"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ModelScope</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">提供支持</font><font style="vertical-align: inherit;">。</font></font></p>
<p align="center" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
        ModelScope Studio </font></font><a href="https://modelscope.cn/studios/CVstudio/cv_human_portrait/summary" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🤖</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> &nbsp; ｜API </font></font><a href="https://help.aliyun.com/zh/dashscope/developer-reference/facechain-quick-start" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🔥</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> &nbsp; ｜ API 示例应用程序</font></font><a href="https://tongyi.aliyun.com/wanxiang/app/portrait-gallery" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🔥</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> &nbsp; | SD WebUI ｜ HuggingFace 空间</font></font><a href="https://huggingface.co/spaces/modelscope/FaceChain" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🤗</font></font></a>&nbsp; 
</p>
<br>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/modelscope/facechain/blob/main/resources/git_cover.jpg"><img src="https://github.com/modelscope/facechain/raw/main/resources/git_cover.jpg" alt="图像" style="max-width: 100%;"></a></p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">消息</font></font></h1><a id="user-content-news" class="anchor" aria-label="永久链接：新闻" href="#news"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们的工作</font></font><a href="https://arxiv.org/abs/2403.01901" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain-ImagineID</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><a href="https://arxiv.org/abs/2403.06775" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain-SuDe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">被CVPR 2024录用！ （世界标准时间 2024 年 2 月 27 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🏆🏆🏆阿里巴巴年度优秀开源项目、阿里巴巴年度开源先锋（刘洋、孙百贵）。 （世界标准时间 2024 年 1 月 20 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们与NUS团队合作的</font></font><a href="https://github.com/henryqin1997/InfoBatch"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">InfoBatch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">工作被ICLR 2024（Oral）接收！ </font><font style="vertical-align: inherit;">（世界标准时间 2024 年 1 月 16 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🏆OpenAtom 2023 年快速增长开源项目奖。 （世界标准时间 2023 年 12 月 20 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加SDXL管线🔥🔥🔥，图像细节明显改善。 （世界标准时间 2023 年 11 月 22 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支持超分辨率🔥🔥🔥，提供多种分辨率选择（512 </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">512、768</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 768、1024 1024、2048 </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2048</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。 （世界标准时间 2023 年 11 月 13 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🏆FaceChain入选</font></font><a href="https://www.benchcouncil.org/evaluation/opencs/annual.html#Institutions" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BenchCouncil Open100（2022-2023）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">年度排名。 （世界标准时间 2023 年 11 月 8 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加虚拟试穿模块。 （世界标准时间 2023 年 10 月 27 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加wanx版本</font></font><a href="https://tongyi.aliyun.com/wanxiang/app/portrait-gallery" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在线免费应用程序</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。 （世界标准时间 2023 年 10 月 26 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🏆1024程序员节AIGC应用工具最具商业价值奖。 （2023 年 10 月 24 日，2023 年世界标准时间）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在 stable-diffusion-webui🔥🔥🔥 中支持 FaceChain。 （世界标准时间 2023 年 10 月 13 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">适用于单人和双人的高性能修复，简化用户界面。 （世界标准时间 2023 年 9 月 9 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">更多技术细节可以参见</font></font><a href="https://arxiv.org/abs/2308.14256" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">论文</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。 （世界标准时间 2023 年 8 月 30 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加 Lora 训练的验证和集成，以及 InpaintTab（暂时隐藏在 gradio 中）。 （世界标准时间 2023 年 8 月 28 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加姿态控制模块。 （世界标准时间 2023 年 8 月 27 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加强大的人脸lora训练模块，增强一张图片训练和风格lora混合的性能。 （世界标准时间 2023 年 8 月 27 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HuggingFace 空间现已上线！您可以直接通过</font></font><a href="https://huggingface.co/spaces/modelscope/FaceChain" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🤗</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">体验FaceChain </font><font style="vertical-align: inherit;">      （2023年8月25日UTC）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">添加很棒的提示！参考：</font></font><a href="/modelscope/facechain/blob/main/resources/awesome-prompts-facechain.txt"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">awesome-prompts-facechain</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">    （UTC时间2023年8月18日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">即插即用支持一系列新款式机型。 （世界标准时间 2023 年 8 月 16 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支持自定义提示。 （世界标准时间 2023 年 8 月 16 日）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Colab 笔记本现已上市！您可以直接体验FaceChain   </font></font><a href="https://colab.research.google.com/github/modelscope/facechain/blob/main/facechain_demo.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/f5e0d0538a9c2972b5d413e0ace04cecd8efd828d133133933dfffec282a4e1b/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="在 Colab 中打开" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width: 100%;"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。 （世界标准时间 2023 年 8 月 15 日）</font></font></li>
</ul>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">待办事项清单</font></font></h1><a id="user-content-to-do-list" class="anchor" aria-label="永久链接：待办事项列表" href="#to-do-list"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">开发免训练方法，使在cpu上运行成为可能。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">开发RLHF方法，使其质量更高。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">提供新风格lora的训练脚本。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支持更多风格lora（比如Civitai上的）。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支持更多美颜修饰效果。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">提供更多有趣的应用。</font></font></li>
</ul>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">引文</font></font></h1><a id="user-content-citation" class="anchor" aria-label="永久链接：引文" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果 FaceChain 对您的研究有帮助，请在您的出版物中引用它</font></font></p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code>@article{liu2023facechain,
  title={FaceChain: A Playground for Identity-Preserving Portrait Generation},
  author={Liu, Yang and Yu, Cheng and Shang, Lei and Wu, Ziheng and 
          Wang, Xingjun and Zhao, Yuze and Zhu, Lin and Cheng, Chen and 
          Chen, Weitao and Xu, Chao and Xie, Haoyu and Yao, Yuan and 
          Zhou,  Wenmeng and Chen Yingda and Xie, Xuansong and Sun, Baigui},
  journal={arXiv preprint arXiv:2308.14256},
  year={2023}
}
</code></pre><div class="zeroclipboard-container">
    
  </div></div>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">安装</font></font></h1><a id="user-content-installation" class="anchor" aria-label="永久链接：安装" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">兼容性验证</font></font></h2><a id="user-content-compatibility-verification" class="anchor" aria-label="永久链接：兼容性验证" href="#compatibility-verification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们已在以下环境中验证了 e2e 执行：</font></font></p>
<ul dir="auto">
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">蟒蛇：py3.8、py3.10</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">火炬：火炬2.0.0，火炬2.0.1</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CUDA：11.7</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">库德恩：8+</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">操作系统：Ubuntu 20.04、CentOS 7.9</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">显卡：Nvidia-A10 24G</font></font></li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">资源需求</font></font></h2><a id="user-content-resource-requirement" class="anchor" aria-label="永久链接：资源需求" href="#resource-requirement"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPU：约19G</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">磁盘：约50GB</font></font></li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">安装指南</font></font></h2><a id="user-content-installation-guide" class="anchor" aria-label="永久链接：安装指南" href="#installation-guide"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支持以下安装方式：</font></font></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.ModelScope笔记本【推荐】</font></font></h3><a id="user-content-1-modelscope-notebookrecommended" class="anchor" aria-label="永久链接： 1. ModelScope笔记本【推荐】" href="#1-modelscope-notebookrecommended"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ModelScope Notebook 提供免费层，允许 ModelScope 用户以最少的设置运行 FaceChain 应用程序，请参阅</font></font><a href="https://modelscope.cn/my/mynotebook/preset" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ModelScope Notebook</font></font></a></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"><span class="pl-c">#</span> Step1: 我的notebook -&gt; PAI-DSW -&gt; GPU环境</span>
<span class="pl-c"><span class="pl-c">#</span> Note: Please use: ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0</span>

<span class="pl-c"><span class="pl-c">#</span> Step2: Entry the Notebook cell，clone FaceChain from github:</span>
<span class="pl-k">!</span>GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1

<span class="pl-c"><span class="pl-c">#</span> Step3: Change the working directory to facechain, and install the dependencies:</span>
import os
os.chdir(<span class="pl-s"><span class="pl-pds">'</span>/mnt/workspace/facechain<span class="pl-pds">'</span></span>)    <span class="pl-c"><span class="pl-c">#</span> You may change to your own path</span>
<span class="pl-en">print(os.getcwd</span>())

<span class="pl-k">!</span>pip3 install gradio==3.50.2
<span class="pl-k">!</span>pip3 install controlnet_aux==0.0.6
<span class="pl-k">!</span>pip3 install python-slugify
<span class="pl-k">!</span>pip3 install onnxruntime==1.15.1
<span class="pl-k">!</span>pip3 install edge-tts
<span class="pl-k">!</span>pip3 install modelscope==1.10.0

<span class="pl-c"><span class="pl-c">#</span> Step4: Start the app service, click "public URL" or "local URL", upload your images to </span>
<span class="pl-c"><span class="pl-c">#</span> train your own model and then generate your digital twin.</span>
<span class="pl-k">!</span>python3 app.py
</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# Step1: 我的notebook -> PAI-DSW -> GPU环境
# Note: Please use: ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0

# Step2: Entry the Notebook cell，clone FaceChain from github:
!GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1

# Step3: Change the working directory to facechain, and install the dependencies:
import os
os.chdir('/mnt/workspace/facechain')    # You may change to your own path
print(os.getcwd())

!pip3 install gradio==3.50.2
!pip3 install controlnet_aux==0.0.6
!pip3 install python-slugify
!pip3 install onnxruntime==1.15.1
!pip3 install edge-tts
!pip3 install modelscope==1.10.0

# Step4: Start the app service, click &quot;public URL&quot; or &quot;local URL&quot;, upload your images to 
# train your own model and then generate your digital twin.
!python3 app.py
" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">或者，您也可以购买</font></font><a href="https://www.aliyun.com/activity/bigdata/pai/dsw" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PAI-DSW</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">实例（使用 A10 资源），并选择 ModelScope 映像来按照类似的步骤运行 FaceChain。</font></font></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2. 码头工人</font></font></h3><a id="user-content-2-docker" class="anchor" aria-label="永久链接：2.Docker" href="#2-docker"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果您熟悉使用docker，我们推荐使用这种方式：</font></font></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"><span class="pl-c">#</span> Step1: Prepare the environment with GPU on local or cloud, we recommend to use Alibaba Cloud ECS, refer to: https://www.aliyun.com/product/ecs</span>

<span class="pl-c"><span class="pl-c">#</span> Step2: Download the docker image (for installing docker engine, refer to https://docs.docker.com/engine/install/）</span>
<span class="pl-c"><span class="pl-c">#</span> For China Mainland users:</span>
docker pull registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0
<span class="pl-c"><span class="pl-c">#</span> For users outside China Mainland:</span>
docker pull registry.us-west-1.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0

<span class="pl-c"><span class="pl-c">#</span> Step3: run the docker container</span>
docker run -it --name facechain -p 7860:7860 --gpus all registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0 /bin/bash
<span class="pl-c"><span class="pl-c">#</span> Note: you may need to install the nvidia-container-runtime, follow the instructions:</span>
<span class="pl-c"><span class="pl-c">#</span> 1. Install nvidia-container-runtime：https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html</span>
<span class="pl-c"><span class="pl-c">#</span> 2. sudo systemctl restart docker</span>

<span class="pl-c"><span class="pl-c">#</span> Step4: Install the gradio in the docker container:</span>
pip3 install gradio==3.50.2
pip3 install controlnet_aux==0.0.6
pip3 install python-slugify
pip3 install onnxruntime==1.15.1
pip3 install edge-tts
pip3 install modelscope==1.10.0

<span class="pl-c"><span class="pl-c">#</span> Step5 clone facechain from github</span>
GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1
<span class="pl-c1">cd</span> facechain
python3 app.py
<span class="pl-c"><span class="pl-c">#</span> Note: FaceChain currently assume single-GPU, if your environment has multiple GPU, please use the following instead:</span>
<span class="pl-c"><span class="pl-c">#</span> CUDA_VISIBLE_DEVICES=0 python3 app.py</span>

<span class="pl-c"><span class="pl-c">#</span> Step6</span>
Run the app server: click <span class="pl-s"><span class="pl-pds">"</span>public URL<span class="pl-pds">"</span></span> --<span class="pl-k">&gt;</span> <span class="pl-k">in</span> the form of: https://xxx.gradio.live</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# Step1: Prepare the environment with GPU on local or cloud, we recommend to use Alibaba Cloud ECS, refer to: https://www.aliyun.com/product/ecs

# Step2: Download the docker image (for installing docker engine, refer to https://docs.docker.com/engine/install/）
# For China Mainland users:
docker pull registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0
# For users outside China Mainland:
docker pull registry.us-west-1.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0

# Step3: run the docker container
docker run -it --name facechain -p 7860:7860 --gpus all registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0 /bin/bash
# Note: you may need to install the nvidia-container-runtime, follow the instructions:
# 1. Install nvidia-container-runtime：https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
# 2. sudo systemctl restart docker

# Step4: Install the gradio in the docker container:
pip3 install gradio==3.50.2
pip3 install controlnet_aux==0.0.6
pip3 install python-slugify
pip3 install onnxruntime==1.15.1
pip3 install edge-tts
pip3 install modelscope==1.10.0

# Step5 clone facechain from github
GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1
cd facechain
python3 app.py
# Note: FaceChain currently assume single-GPU, if your environment has multiple GPU, please use the following instead:
# CUDA_VISIBLE_DEVICES=0 python3 app.py

# Step6
Run the app server: click &quot;public URL&quot; --> in the form of: https://xxx.gradio.live" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3.Conda虚拟环境</font></font></h3><a id="user-content-3-conda-virtual-environment" class="anchor" aria-label="永久链接：3.Conda 虚拟环境" href="#3-conda-virtual-environment"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用conda虚拟环境，并参考</font></font><a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anaconda</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">来管理您的依赖项。安装完成后，执行以下命令：（注：mmcv对环境要求严格，某些情况下可能不兼容，建议使用Docker。）</font></font></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>conda create -n facechain python=3.10    <span class="pl-c"><span class="pl-c">#</span> Verified environments: 3.10 and 3.8 recommend 3.10</span>
conda activate facechain

GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1
<span class="pl-c1">cd</span> facechain

pip3 install -r requirements.txt
pip3 install -U openmim 
<span class="pl-c"><span class="pl-c">#</span> install mmcv-full with, ref: https://mmcv.readthedocs.io/en/latest/get_started/installation.html</span>
mim install mmcv-full==1.7.2
<span class="pl-c"><span class="pl-c">#</span> Other version please reference mmcv official site.</span>

<span class="pl-c"><span class="pl-c">#</span> Navigate to the facechain directory and run:</span>
python3 app.py
<span class="pl-c"><span class="pl-c">#</span> Note: FaceChain currently assume single-GPU, if your environment has multiple GPU, please use the following instead:</span>
<span class="pl-c"><span class="pl-c">#</span> CUDA_VISIBLE_DEVICES=0 python3 app.py</span>

<span class="pl-c"><span class="pl-c">#</span> Finally, click on the URL generated in the log to access the web page.</span></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="conda create -n facechain python=3.10    # Verified environments: 3.10 and 3.8 recommend 3.10
conda activate facechain

GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1
cd facechain

pip3 install -r requirements.txt
pip3 install -U openmim 
# install mmcv-full with, ref: https://mmcv.readthedocs.io/en/latest/get_started/installation.html
mim install mmcv-full==1.7.2
# Other version please reference mmcv official site.

# Navigate to the facechain directory and run:
python3 app.py
# Note: FaceChain currently assume single-GPU, if your environment has multiple GPU, please use the following instead:
# CUDA_VISIBLE_DEVICES=0 python3 app.py

# Finally, click on the URL generated in the log to access the web page." tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注意</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：应用服务成功启动后，进入日志中的URL，进入“图片定制”选项卡，点击“选择要上传的图片”，并选择至少一张带有人脸的图片。然后，单击“开始训练”开始模型训练。训练完成后，日志中会有相应的显示。然后，切换到“图像体验”选项卡并单击“开始推理”以生成您自己的数字图像。</font></font></p>
<p dir="auto"><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注意</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">对于Windows用户，您应该注意以下步骤：</font></font></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"><span class="pl-c">#</span> ref:https://mmcv.readthedocs.io/en/latest/get_started/installation.html</span>
install mmcv-full by mim: mim install mmcv-full==1.7.2</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# ref:https://mmcv.readthedocs.io/en/latest/get_started/installation.html
install mmcv-full by mim: mim install mmcv-full==1.7.2" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果您想使用该</font></font><code>Audio Driven Talking Head</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">选项卡，请参阅</font></font><a href="/modelscope/facechain/blob/main/doc/installation_for_talkinghead.md"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation_for_talkinghead</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">中的安装指南。</font></font></strong></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4.Colab笔记本</font></font></h3><a id="user-content-4-colab-notebook" class="anchor" aria-label="永久链接：4. Colab 笔记本" href="#4-colab-notebook"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<table>
<thead>
<tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">科拉布</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信息</font></font></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://colab.research.google.com/github/modelscope/facechain/blob/main/facechain_demo.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/f5e0d0538a9c2972b5d413e0ace04cecd8efd828d133133933dfffec282a4e1b/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="在 Colab 中打开" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width: 100%;"></a></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Colab 上的 FaceChain 安装</font></font></td>
</tr>
</tbody>
</table>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5. 稳定扩散webui</font></font></h3><a id="user-content-5-stable-diffusion-webui" class="anchor" aria-label="永久链接：5. stable-diffusion-webui" href="#5-stable-diffusion-webui"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">选择</font></font><code>Extensions Tab</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，然后选择</font></font><code>Install From URL</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（官方插件集成是 u）。
</font></font><a target="_blank" rel="noopener noreferrer" href="/modelscope/facechain/blob/main/resources/sdwebui_install.png"><img src="/modelscope/facechain/raw/main/resources/sdwebui_install.png" alt="图像" style="max-width: 100%;"></a></p>
</li>
<li>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">切换到</font></font><code>Installed</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，勾选 FaceChain 插件，然后点击</font></font><code>Apply and restart UI</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。
</font></font><a target="_blank" rel="noopener noreferrer" href="/modelscope/facechain/blob/main/resources/sdwebui_restart.png"><img src="/modelscope/facechain/raw/main/resources/sdwebui_restart.png" alt="图像" style="max-width: 100%;"></a></p>
</li>
<li>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">页面刷新后出现Tab</font></font><code>FaceChain</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">表示安装成功。
</font></font><a target="_blank" rel="noopener noreferrer" href="/modelscope/facechain/blob/main/resources/sdwebui_success.png"><img src="/modelscope/facechain/raw/main/resources/sdwebui_success.png" alt="图像" style="max-width: 100%;"></a></p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">脚本执行</font></font></h1><a id="user-content-script-execution" class="anchor" aria-label="永久链接：脚本执行" href="#script-execution"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain支持在python环境下直接训练和推理。在克隆的文件夹中运行以下命令开始训练：</font></font></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>PYTHONPATH=. sh train_lora.sh <span class="pl-s"><span class="pl-pds">"</span>ly261666/cv_portrait_model<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>v2.0<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>film/film<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>./imgs<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>./processed<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>./output<span class="pl-pds">"</span></span></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="PYTHONPATH=. sh train_lora.sh &quot;ly261666/cv_portrait_model&quot; &quot;v2.0&quot; &quot;film/film&quot; &quot;./imgs&quot; &quot;./processed&quot; &quot;./output&quot;" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参数说明：</font></font></p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre lang="text" class="notranslate"><code>ly261666/cv_portrait_model: The stable diffusion base model of the ModelScope model hub, which will be used for training, no need to be changed.
v2.0: The version number of this base model, no need to be changed
film/film: This base model may contains multiple subdirectories of different styles, currently we use film/film, no need to be changed
./imgs: This parameter needs to be replaced with the actual value. It means a local file directory that contains the original photos used for training and generation
./processed: The folder of the processed images after preprocessing, this parameter needs to be passed the same value in inference, no need to be changed
./output: The folder where the model weights stored after training, no need to be changed
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="ly261666/cv_portrait_model: The stable diffusion base model of the ModelScope model hub, which will be used for training, no need to be changed.
v2.0: The version number of this base model, no need to be changed
film/film: This base model may contains multiple subdirectories of different styles, currently we use film/film, no need to be changed
./imgs: This parameter needs to be replaced with the actual value. It means a local file directory that contains the original photos used for training and generation
./processed: The folder of the processed images after preprocessing, this parameter needs to be passed the same value in inference, no need to be changed
./output: The folder where the model weights stored after training, no need to be changed" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">等待 5-20 分钟即可完成训练。用户还可以调整其他训练超参数。训练支持的超参数可以在 的文件中查看</font></font><code>train_lora.sh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，或者完整的超参数列表在 中</font></font><code>facechain/train_text_to_image_lora.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">推理时，请编辑run_inference.py中的代码：</font></font></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># Use depth control, default False, only effective when using pose control</span>
<span class="pl-s1">use_depth_control</span> <span class="pl-c1">=</span> <span class="pl-c1">False</span>
<span class="pl-c"># Use pose control, default False</span>
<span class="pl-s1">use_pose_model</span> <span class="pl-c1">=</span> <span class="pl-c1">False</span>
<span class="pl-c"># The path of the image for pose control, only effective when using pose control</span>
<span class="pl-s1">pose_image</span> <span class="pl-c1">=</span> <span class="pl-s">'poses/man/pose1.png'</span>
<span class="pl-c"># Fill in the folder of the images after preprocessing above, it should be the same as during training</span>
<span class="pl-s1">processed_dir</span> <span class="pl-c1">=</span> <span class="pl-s">'./processed'</span>
<span class="pl-c"># The number of images to generate in inference</span>
<span class="pl-s1">num_generate</span> <span class="pl-c1">=</span> <span class="pl-c1">5</span>
<span class="pl-c"># The stable diffusion base model used in training, no need to be changed</span>
<span class="pl-s1">base_model</span> <span class="pl-c1">=</span> <span class="pl-s">'ly261666/cv_portrait_model'</span>
<span class="pl-c"># The version number of this base model, no need to be changed</span>
<span class="pl-s1">revision</span> <span class="pl-c1">=</span> <span class="pl-s">'v2.0'</span>
<span class="pl-c"># This base model may contains multiple subdirectories of different styles, currently we use film/film, no need to be changed</span>
<span class="pl-s1">base_model_sub_dir</span> <span class="pl-c1">=</span> <span class="pl-s">'film/film'</span>
<span class="pl-c"># The folder where the model weights stored after training, it must be the same as during training</span>
<span class="pl-s1">train_output_dir</span> <span class="pl-c1">=</span> <span class="pl-s">'./output'</span>
<span class="pl-c"># Specify a folder to save the generated images, this parameter can be modified as needed</span>
<span class="pl-s1">output_dir</span> <span class="pl-c1">=</span> <span class="pl-s">'./generated'</span>
<span class="pl-c"># Use Chinese style model, default False</span>
<span class="pl-s1">use_style</span> <span class="pl-c1">=</span> <span class="pl-c1">False</span></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# Use depth control, default False, only effective when using pose control
use_depth_control = False
# Use pose control, default False
use_pose_model = False
# The path of the image for pose control, only effective when using pose control
pose_image = 'poses/man/pose1.png'
# Fill in the folder of the images after preprocessing above, it should be the same as during training
processed_dir = './processed'
# The number of images to generate in inference
num_generate = 5
# The stable diffusion base model used in training, no need to be changed
base_model = 'ly261666/cv_portrait_model'
# The version number of this base model, no need to be changed
revision = 'v2.0'
# This base model may contains multiple subdirectories of different styles, currently we use film/film, no need to be changed
base_model_sub_dir = 'film/film'
# The folder where the model weights stored after training, it must be the same as during training
train_output_dir = './output'
# Specify a folder to save the generated images, this parameter can be modified as needed
output_dir = './generated'
# Use Chinese style model, default False
use_style = False" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">然后执行：</font></font></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>python run_inference.py</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="python run_inference.py" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">您可以在 中找到生成的个人数字图像照片</font></font><code>output_dir</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">算法介绍</font></font></h1><a id="user-content-algorithm-introduction" class="anchor" aria-label="永久链接：算法介绍" href="#algorithm-introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">架构概览</font></font></h2><a id="user-content-architectural-overview" class="anchor" aria-label="永久链接：架构概述" href="#architectural-overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">个人肖像生成的能力围绕稳定扩散模型的文本到图像的能力而发展。我们考虑影响个人肖像生成效果的主要因素：肖像风格信息和用户性格信息。为此，我们使用离线训练的风格 LoRA 模型和在线训练的面部 LoRA 模型来学习上述信息。 LoRA 是一种可训练参数较少的微调模型。在Stable Diffusion中，可以通过少量输入图像进行文本生成图像训练的方式将输入图像的信息注入到LoRA模型中。因此，个人肖像模型的能力分为训练和推理阶段。训练阶段生成图像和文本标签数据用于微调Stable Diffusion模型，并获得人脸LoRA模型。推理阶段根据人脸LoRA模型和风格LoRA模型生成个人肖像图像。</font></font></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="/modelscope/facechain/blob/main/resources/framework_eng.jpg"><img src="/modelscope/facechain/raw/main/resources/framework_eng.jpg" alt="图像" style="max-width: 100%;"></a></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">训练</font></font></h2><a id="user-content-training" class="anchor" aria-label="永久链接：培训" href="#training"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">输入：用户上传的包含清晰面部区域的图像</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">输出：人脸LoRA模型</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">描述：首先，我们使用基于方向判断的图像旋转模型和基于人脸检测和关键点模型的人脸细化旋转方法对用户上传的图像进行处理，获得包含正面人脸的图像。接下来，我们使用人体解析模型和人像美化模型来获得高质量的人脸训练图像。然后，我们使用人脸属性模型和文本标注模型，结合标签后处理方法，为训练图像生成细粒度的标签。最后，我们利用上述图像和标签数据对Stable Diffusion模型进行微调，得到人脸LoRA模型。</font></font></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">推理</font></font></h2><a id="user-content-inference" class="anchor" aria-label="永久链接： 推理" href="#inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">输入：训练阶段用户上传的图片，预设生成个人肖像的输入提示词</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">输出：个人肖像图像</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">描述：首先，我们将面部 LoRA 模型和样式 LoRA 模型的权重融合到稳定扩散模型中。接下来，我们利用Stable Diffusion模型的文本生成图像功能，根据预设的输入提示词初步生成个人肖像图像。然后我们使用人脸融合模型进一步改善上述人像图像的人脸细节。通过人脸质量评估模型从训练图像中选择用于融合的模板人脸。最后，我们利用人脸识别模型计算生成的人像图像与模板人脸的相似度，并以此对人像图像进行排序，输出排名第一的个人人像图像作为最终的输出结果。</font></font></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">型号列表</font></font></h2><a id="user-content-model-list" class="anchor" aria-label="永久链接：型号列表" href="#model-list"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceChain中使用的模型：</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[1] 人脸检测模型DamoFD：</font></font><a href="https://modelscope.cn/models/damo/cv_ddsar_face-detection_iclr23-damofd" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://modelscope.cn/models/damo/cv_ddsar_face-detection_iclr23-damofd</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[2] 图像旋转模型，由 ModelScope 工作室提供</font></font></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[3] 人体解析模型M2FP：</font></font><a href="https://modelscope.cn/models/damo/cv_resnet101_image-multiple-human-parsing" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://modelscope.cn/models/damo/cv_resnet101_image-multiple- human-parsing</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[4] 皮肤修饰模型ABPN：</font></font><a href="https://www.modelscope.cn/models/damo/cv_unet_skin_retouching_torch" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.modelscope.cn/models/damo/cv_unet_skin_retouching_torch</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[5] 人脸属性识别模型FairFace：</font></font><a href="https://modelscope.cn/models/damo/cv_resnet34_face-attribute-recognition_fairface" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://modelscope.cn/models/damo/cv_resnet34_face-attribute-recognition_fairface</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[6] DeepDanbooru模型：</font></font><a href="https://github.com/KichangKim/DeepDanbooru"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://github.com/KichangKim/DeepDanbooru</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[7] 人脸质量评估常见问题解答：</font></font><a href="https://modelscope.cn/models/damo/cv_manual_face-quality-assessment_fqa" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://modelscope.cn/models/damo/cv_manual_face-quality-assessment_fqa</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[8] 人脸融合模型：</font></font><a href="https://www.modelscope.cn/models/damo/cv_unet_face_fusion_torch" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.modelscope.cn/models/damo/cv_unet_face_fusion_torch</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[9] 人脸识别模型RTS：</font></font><a href="https://modelscope.cn/models/damo/cv_ir_face-recognition-ood_rts" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://modelscope.cn/models/damo/cv_ir_face-recognition-ood_rts</font></font></a></p>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[10] 说话头像模型：</font></font><a href="https://modelscope.cn/models/wwd123/sadtalker" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://modelscope.cn/models/wwd123/sadtalker</font></font></a></p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">更多信息</font></font></h1><a id="user-content-more-information" class="anchor" aria-label="永久链接：更多信息" href="#more-information"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><a href="https://github.com/modelscope/modelscope/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">模型范围库</font></font></a></li>
</ul>
<p dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&ZeroWidthSpace; ModelScope Library 为构建ModelScope的模型生态系统提供了基础，包括将各种模型集成到ModelScope中的接口和实现。</font></font></p>
<ul dir="auto">
<li><a href="https://modelscope.cn/docs/ModelScope%E6%A8%A1%E5%9E%8B%E6%8E%A5%E5%85%A5%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将模型贡献给 ModelScope</font></font></a></li>
</ul>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">执照</font></font></h1><a id="user-content-license" class="anchor" aria-label="永久链接：许可证" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font style="vertical-align: inherit;"></font><a href="https://github.com/modelscope/modelscope/blob/master/LICENSE"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">该项目根据Apache 许可证（版本 2.0）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">获得许可</font><font style="vertical-align: inherit;">。</font></font></p>
</article></div>
